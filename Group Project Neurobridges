# Representation Dispersion Across Layers  
## Exploring Symmetry, Representation Dynamics, and Rotation Invariance in Neural Networks  

**Summer School Project – NeuroBridges 2025**  
**Mentors:** Prof. David Hansel, Prof. Yonatan Loewenstein, Prof. Ahmed El Hady  
[https://neurobridges.net/upcoming/program](https://neurobridges.net/upcoming/program)

---

### Overview  

This project investigates representation dispersion and symmetrical states in artificial neural networks, inspired by the RIFF framework introduced by Israel Nelken and collaborators.  

We explored how internal representations evolve and disperse across layers in two different learning contexts:  
1. Reinforcement Learning (RL) – using agents trained in a *GoToDoor* game environment.  
2. Computer Vision – using convolutional neural networks (CNNs) to analyze rotation invariance as a possible manifestation of symmetrical states.  

---

### Objectives  

- Examine representation dispersion across layers in RL agents trained with A2C and PPO algorithms.  
- Investigate whether rotation invariance in CNNs (ResNet vs. AlexNet) can be interpreted as a form of symmetrical representation state.  
- Bridge insights between deep reinforcement learning and representational geometry inspired by neuroscience.  

---

### Methods  

#### Reinforcement Learning Experiments  

- **Environment:** *GoToDoor* — a navigation task where an agent must reach a target door using visual cues.  
- **Agents:** A2C (Advantage Actor-Critic) and PPO (Proximal Policy Optimization).  
- **Analysis:** Representation vectors were extracted across hidden layers, and dispersion, correlation, and symmetry metrics were computed to quantify internal state evolution.  

#### Representation Dispersion Metrics  

Computed measures included:  
- Inter-layer representational distance  
- Within-layer variance  
- Symmetry indices (based on covariance and trajectory overlap between latent representations)  

These metrics quantify how representations diverge or converge across network depth, revealing internal organization patterns.  

#### CNN Rotation Invariance  

Two architectures, AlexNet and ResNet-50, were compared.  
Each model was tested on rotated image datasets to evaluate rotation invariance.  
The working hypothesis was that rotation-invariant representations might correspond to symmetrical representational states, as observed in biological and theoretical models such as RIFF (Nelken et al.).  

---

### Results (Preliminary)  

- In RL agents, representation dispersion increased with depth and training progress, with PPO showing greater internal diversity than A2C.  
- In CNNs, ResNet demonstrated stronger rotation invariance and more structured representations than AlexNet, supporting the hypothesis of symmetrical state organization.  
- Cross-domain comparisons revealed shared geometric properties in representation dynamics between supervised and reinforcement learning systems.  

---

### Scientific Context  

This project builds on the Representation-Induced Functional Framework (RIFF) developed by Israel Nelken, which links symmetrical states in neural populations to robustness and generalization in learning systems.  

By extending these ideas to artificial neural networks, we aim to better understand how symmetry, dispersion, and invariance emerge across architectures and learning paradigms.  

---

### References  

- Nelken, I., et al. (2023). *Representation-Induced Functional Framework (RIFF): Symmetry and Dispersion in Neural Population Codes.*  
- Mnih, V., et al. (2016). *Asynchronous Methods for Deep Reinforcement Learning.* ICML.  
- Schulman, J., et al. (2017). *Proximal Policy Optimization Algorithms.* arXiv:1707.06347.  
- Krizhevsky, A., Sutskever, I., & Hinton, G. (2012). *ImageNet Classification with Deep Convolutional Neural Networks.* NIPS.  
- He, K., et al. (2016). *Deep Residual Learning for Image Recognition.* CVPR.  

---

### Team  

Developed during the NeuroBridges Summer School 2025 by:  
- Hélène Soydemir  
- [Adàn Cruz]  
- [Gautham Venugopal]  
- [Himalaya Girard]  

Supervised by Prof. David Hansel, Prof. Yonatan Loewenstein, Prof. Ahmed El Hady, and Cluny.  
